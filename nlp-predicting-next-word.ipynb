{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#     for dirname, _, filenames in os.walk('/kaggle/input'):\n#          for filename in filenames:\n#              print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-10T09:12:03.948935Z","iopub.execute_input":"2021-12-10T09:12:03.949212Z","iopub.status.idle":"2021-12-10T09:12:03.974401Z","shell.execute_reply.started":"2021-12-10T09:12:03.949135Z","shell.execute_reply":"2021-12-10T09:12:03.973762Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import heapq\nimport matplotlib.pyplot as plt\nfrom nltk.tokenize import RegexpTokenizer\nfrom keras.models import Sequential, load_model\nfrom keras.layers.core import Dense, Activation\nfrom keras.layers import LSTM\nimport pickle\nimport tensorflow as tf\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T09:12:03.976071Z","iopub.execute_input":"2021-12-10T09:12:03.976318Z","iopub.status.idle":"2021-12-10T09:12:10.058594Z","shell.execute_reply.started":"2021-12-10T09:12:03.976284Z","shell.execute_reply":"2021-12-10T09:12:10.057830Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"text=open('../input/nlp-predicting-next-word-dataset/1661-0.txt','r').read().lower()\nprint('length of the corpus is: :', len(text))","metadata":{"execution":{"iopub.status.busy":"2021-12-10T09:12:10.059946Z","iopub.execute_input":"2021-12-10T09:12:10.060221Z","iopub.status.idle":"2021-12-10T09:12:10.089383Z","shell.execute_reply.started":"2021-12-10T09:12:10.060185Z","shell.execute_reply":"2021-12-10T09:12:10.088682Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer = RegexpTokenizer(r'\\w+')\nwords = tokenizer.tokenize(text)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-10T09:12:10.091351Z","iopub.execute_input":"2021-12-10T09:12:10.091796Z","iopub.status.idle":"2021-12-10T09:12:10.131034Z","shell.execute_reply.started":"2021-12-10T09:12:10.091755Z","shell.execute_reply":"2021-12-10T09:12:10.130208Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"unique_words = np.unique(words)\nunique_word_index = dict((c, i) for i, c in enumerate(unique_words))","metadata":{"execution":{"iopub.status.busy":"2021-12-10T09:12:10.132420Z","iopub.execute_input":"2021-12-10T09:12:10.132889Z","iopub.status.idle":"2021-12-10T09:12:10.202050Z","shell.execute_reply.started":"2021-12-10T09:12:10.132844Z","shell.execute_reply":"2021-12-10T09:12:10.201278Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"LENGTH_WORD = 5\nnext_words = []\nprev_words = []\nfor j in range(len(words) - LENGTH_WORD):\n     prev_words.append(words[j:j + LENGTH_WORD])\n     next_words.append(words[j + LENGTH_WORD])","metadata":{"execution":{"iopub.status.busy":"2021-12-10T09:12:10.204644Z","iopub.execute_input":"2021-12-10T09:12:10.205073Z","iopub.status.idle":"2021-12-10T09:12:10.446717Z","shell.execute_reply.started":"2021-12-10T09:12:10.205035Z","shell.execute_reply":"2021-12-10T09:12:10.445931Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X = np.zeros((len(prev_words), LENGTH_WORD, len(unique_words)), dtype=bool)\nY = np.zeros((len(next_words), len(unique_words)), dtype=bool)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T09:12:10.447909Z","iopub.execute_input":"2021-12-10T09:12:10.448155Z","iopub.status.idle":"2021-12-10T09:12:10.453070Z","shell.execute_reply.started":"2021-12-10T09:12:10.448123Z","shell.execute_reply":"2021-12-10T09:12:10.452271Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for i, each_words in enumerate(prev_words):\n   for j, each_word in enumerate(each_words):\n        X[i, j, unique_word_index[each_word]] = 1\n   Y[i, unique_word_index[next_words[i]]] = 1","metadata":{"execution":{"iopub.status.busy":"2021-12-10T09:12:10.454425Z","iopub.execute_input":"2021-12-10T09:12:10.455209Z","iopub.status.idle":"2021-12-10T09:12:12.116359Z","shell.execute_reply.started":"2021-12-10T09:12:10.455171Z","shell.execute_reply":"2021-12-10T09:12:12.115536Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(128, input_shape=(LENGTH_WORD, len(unique_words))))\nmodel.add(Dense(len(unique_words)))\nmodel.add(Activation('softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-12-10T09:12:12.118640Z","iopub.execute_input":"2021-12-10T09:12:12.118904Z","iopub.status.idle":"2021-12-10T09:12:14.743542Z","shell.execute_reply.started":"2021-12-10T09:12:12.118869Z","shell.execute_reply":"2021-12-10T09:12:14.742790Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T09:12:14.744666Z","iopub.execute_input":"2021-12-10T09:12:14.744933Z","iopub.status.idle":"2021-12-10T09:12:14.754237Z","shell.execute_reply.started":"2021-12-10T09:12:14.744900Z","shell.execute_reply":"2021-12-10T09:12:14.753536Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\nhistory = model.fit(X, Y, validation_split=0.05,epochs=50, shuffle=True).history","metadata":{"execution":{"iopub.status.busy":"2021-12-10T09:12:14.755573Z","iopub.execute_input":"2021-12-10T09:12:14.756027Z","iopub.status.idle":"2021-12-10T09:32:20.367695Z","shell.execute_reply.started":"2021-12-10T09:12:14.755991Z","shell.execute_reply":"2021-12-10T09:32:20.366868Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = load_model('../input/nlp-predicting-next-word1/NLP_Predicting_next_word.h5')\n","metadata":{"execution":{"iopub.status.busy":"2021-12-10T09:32:20.369435Z","iopub.execute_input":"2021-12-10T09:32:20.369714Z","iopub.status.idle":"2021-12-10T09:32:21.784896Z","shell.execute_reply.started":"2021-12-10T09:32:20.369677Z","shell.execute_reply":"2021-12-10T09:32:21.784018Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}